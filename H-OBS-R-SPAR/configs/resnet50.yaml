# ResNet-50 Configuration for H-OBS/R-SPAR

# Model Configuration
model:
  name: "resnet50"
  pretrained: true
  num_classes: 1000

# Dataset Configuration
dataset:
  name: "imagenet"
  data_dir: "/data/imagenet"
  image_size: 224
  num_workers: 16
  pin_memory: true

# Training Configuration
training:
  batch_size: 256
  epochs: 100
  optimizer: "SGD"
  learning_rate: 0.1
  momentum: 0.9
  weight_decay: 0.0005
  lr_schedule: "cosine"
  warmup_epochs: 5

# Pruning Configuration
pruning:
  method: "hobs-rspar" # or "depgraph", "autocompress", etc.
  target_flops_reduction: 0.76 # Target 0.24× FLOPs remaining
  target_params_reduction: 0.69 # Target 0.31× params remaining

  # H-OBS specific
  hobs:
    use_kfac: true
    damping: 0.001
    num_batches_sensitivity: 50

  # R-SPAR specific
  rspar:
    num_episodes: 100
    hidden_dim: 256
    learning_rate: 0.0003
    gamma: 0.99
    clip_epsilon: 0.2

  # Adaptive regularization
  regularization:
    lambda_init: 0.01
    tau: 2.5
    lambda_min: 0.0001
    lambda_max: 0.1

# Fine-tuning Configuration
finetuning:
  epochs: 50
  learning_rate: 0.01
  batch_size: 256
  use_knowledge_distillation: true
  kd_temperature: 3.0
  kd_alpha: 0.7

# Evaluation Configuration
evaluation:
  batch_size: 64
  num_iterations_latency: 100
  num_iterations_throughput: 50

# System Configuration
system:
  gpu_id: 0
  fp16: false
  benchmark: true
  deterministic: false

# Experiment Tracking
experiment:
  name: "resnet50_hobs_rspar"
  save_dir: "./results/resnet50"
  log_interval: 100
  save_interval: 10
  random_seeds: [42, 2024, 10086, 520, 1314]
